{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a62d0c-f157-4e8c-8da7-b2f5eb9de394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from Util import get_parking_spots_bboxes, empty_or_not\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f84fbf6-132d-466b-be3d-214f48db62fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Video\n"
     ]
    }
   ],
   "source": [
    "# Load Video\n",
    "cap = cv2.VideoCapture('parking_1920_1080.mp4')\n",
    "if not cap.isOpened():\n",
    "    print('Error: Could not open the Video.')\n",
    "    exit()\n",
    "    \n",
    "#Load mask\n",
    "mask=cv2.imread('mask_1920_1080.png', 0) # read binary\n",
    "if mask is None:\n",
    "    print(\"Error: Mask could not load mask\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "#Calc The deffrence between the frist frame & seconed frame\n",
    "def calc_diff(frame1, frame2):\n",
    "    return np.abs(np.mean(frame1) - np.mean(frame2))\n",
    "previous_frame = None # for store previous frame \n",
    "\n",
    "#Connect components of the mask in the img\n",
    "connected_components = cv2.connectedComponentsWithStats(mask, 4, cv2.CV_32S) # for analysis the mask and take the coordinates.\n",
    "boxes = get_parking_spots_bboxes(connected_components) # func to select the bboxes \n",
    "boxes_status = [None for j in boxes] # list to store the box status\n",
    "diff = [None for j in boxes] # List to store The deffrence between the frist frame & seconed frame\n",
    "step= 40\n",
    "img_num = 0\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        print('End of Video')\n",
    "        break\n",
    "\n",
    "    # This to calc the diffrence between frames\n",
    "    if img_num % step == 0 and previous_frame is not None: # update frame and to make sure that already have previous frame to calc the diffrence.\n",
    "        for box_index, box in enumerate(boxes):\n",
    "            x1, y1, w, h= box\n",
    "            box_crop = img[y1:y1 + h, x1:x1 + w, :] # to crop the img(x-axis, y-axis) and select RGB\n",
    "            diff[box_index] = calc_diff(box_crop, previous_frame[y1:y1 + h, x1:x1 + w, :]) # this crop the box in currently frame and compare with the previous frame\n",
    "\n",
    "    if img_num % step == 0:\n",
    "        if previous_frame is None:\n",
    "            arr = range(len(boxes)) # make indexes to start the comparisons.\n",
    "        else:\n",
    "            arr = [j for j in np.argsort(diff) if diff[j] / np.amax(diff) > 0.4] # that make Ascending order and the goal of this to update the boxes that have changed up to 40%\n",
    "                                                                                                      \n",
    "        for box_index in arr:\n",
    "            box = boxes[box_index] # take the coordinates of the current box\n",
    "            x1, y1, w, h= box\n",
    "            box_crop = img[y1:y1 + h, x1:x1 + w, :]\n",
    "            box_status = empty_or_not(box_crop)\n",
    "            boxes_status[box_index] = box_status\n",
    "\n",
    "    if img_num % step == 0:\n",
    "        previous_frame = img.copy() # to store the currently frame as the previous frame after finish the process.\n",
    "\n",
    "\n",
    "    for box_index, box in enumerate(boxes):\n",
    "        box_status = boxes_status[box_index]\n",
    "        x1, y1, w, h = boxes[box_index]   \n",
    "        if box_status:\n",
    "            cv2.rectangle(img, (x1, y1), (x1+w, y1+h), (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv2.rectangle(img, (x1, y1), (x1+w, y1+h), (0, 0, 255), 2)\n",
    "\n",
    "    cv2.rectangle(img, (80, 20), (550, 80), (0, 0, 0), -1)\n",
    "    cv2.putText(img, 'Available Spots: {} / {}'.format(str(sum(boxes_status)), str(len(boxes_status))), \n",
    "                (100, 60),cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('image', img)\n",
    "\n",
    "    # Wait for 1 millisecond and check if the user pressed the 'q' key to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    img_num+= 1\n",
    "# Release the video capture object and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9963ae47-8822-4d9d-b2df-419116dde036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyNewVenv",
   "language": "python",
   "name": "mynewvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
